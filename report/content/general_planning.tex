\section{General planning}
	The idea of using a general planner is that its possible to solve the problem efficiently, without building a planner from scratch for each problem. The general planer will however nearly always be less efficient than an planner for the specific problem. %This is due to...
	The main question is therefore if the general planner can solve the problem efficiently enough to be useful.

	To begin solving the problem with a general planner, the domain needs to be described in a Planning languages. In this case PDDL is suitable choice since it is a expressive language and used for the IPC, and there therefore exists a series of planners that support the language.
 

%	single agent planing
	  
%	complete PDDL not fully supported by most planners
	
	The general planner there will be used is Fast Downward, Fast Downward was chosen due to it being open source and it has done well in several IPC, and must therefore be considered one of the better planer out there, even though it only support a subset (PDDL 2.2 level 1 + action cost) of the complete PDDL.
	One of the things that differentiate Fast Downward from other planners is that it dosnt directly use PDDL for the planning but instead translates it first. 
 
 \subsection{PDDL}
	
	The chosen planer is Fast Downward, which is limited to PDDL 2.2 level 1 + action cost, therefore this subset of PDDL will be used.

	\subsubsection{The Astro kid world}
	Astro Kid is a discrete world where everything moves in a 2d grid, each point in the world is represented in PDDL as an object and its location is defined relative to its neighbours. Everything else's locations in the domain is defined relative to these locations.
	
	
	When looking at the Astro Kid world, its worth noting the main areas where it differentiates from classical planner domains like the gripper. These areas is concurrent actions and continuous effects. 
	The continuous actions are where the planner cant change what is happening to a object before the action has ended, these actions is things such as falling, sliding and robots walking. They are handled by locking an objects to a given course of actions by creating a predicate with it. The created predicate is used as a guard to ensure that other actions dosnt interact with the object and only the locked action can be performed on the object.
	
	
	%To allow the planner to more efficiently solve problems in the domain, it is not possible to allow a continuous action to completely stop before the next action starts.
	
	%	worth of note is that even though its a single agent world, multiple things can happen concurrent. this i mainly due to that some actions have continuous effects.
	
	To allow the planner to more efficiently solve problems  in the domain, continuous action should not be allow to completely stop before the next action starts. This is to avoid the agent standing still will something moves somewhere else. Therefore some kind of parallelism is needs. PDDL doesn't directly allow concurrent actions, unless they are changed into a single action. This could be done by having a action for each possible combination of objects moving, This approach would however leads to an explosion of possible actions since the number of actions would then be depend on the number of objects that can have a continuous effect. The scaling would therefore be terrible. The approach might however still work, if working under the assumption that the number of objects in the problem is fairly limited. Another approach and the chosen one, is to focus on that there basically are two types of actions in the domain, the ones where the planner has a choice (player action) and actions which are consequences/updates of earlier actions. The main idea is therefore to separate the domain into input/choice and update, and then enforcing a ordering of the actions so a input/choice is always followed by an update. The ordering of actions can be enforced by using flags.	
		
	The update step is itself split up into multiple parts with a strict ordering, to enforce that the concurrent actions interact correctly with each others. The update step is separated into, removing objects, changing direction of objects, moving objects, collecting items, opening/closing gates, teleportation. And universal quantifiers are used to ensure all the continuous effects are applied.

	 
\subsection{Fast downward}
	There are various ways of tweaking the performance of the planner. The two most obvious ways of doing this, is changing the parameters of the planner and changing the PDDL domain to fit the planners strengths better.
	
	\subsubsection{Domain}
	Test have shown that use of universal quantifiers have a large impact on the prepossessing time. Therefore there is created a variation of the domain where a single the universal quantifiers are replaced by an existential quantifier and an extra action(s).(code can be found at Appendix \ref{Domain_Variation})
	
	\begin{table}[h]
		\centering
		\caption{problem 4}
		\label{prob4}
		\begin{tabular}{lllll}
			& forall & simple  \\
			total Time & 26.2 & 136.2 \\
			translator Time& 21.9 & 6.6 \\
			
			
			relevant atoms & 8872 & 12968\\
			auxiliary atoms & 16959& 18807\\
			final queue length &25831 & 31775\\
			total queue pushes &58904 & 68537\\
			axioms & 1 & 132652 \\ 
			peak memory & 100568 KB & 208356 KB\\ 
			task size & 42751 & 573269\\
				
				
			preprocessing Time& 4.2 & 127.4 \\
			necessary operators & 7292 & 7337\\
				
				
			search Time & 0.1 & 2.2 \\
		\end{tabular}
	\end{table}
	%insert table of running times
	When running the different versions of the domain on various problems, one thing becomes clear, the total times varies greatly depending on the domain and level combination (table \ref{times}). However when looking at the results (table \ref{prob4}), what shows is that the use of universal quantifiers greatly increases the instantiation/translation time. This is where the grounding of the atoms takes place.
	
	Replacing the universal quantifiers ensures a quicker instantiation/translation, but it has the cost of the number of axioms exploding, and in general the number of atoms growing by 5-20\%, which in the end can greatly hampers the preprocessing that generates the Causal graph.
	
	The tendency seams to be that the more movable objects the better the version with universal quantifiers does. Generally this optimization/variation of the domain only really shines when the problem is "small" and isnt therefore useful on the different levels in Astro Kid.
	

	When looking at the data its also worth taking note of that most of the time is not spend in search, as one would expect for a planner, but instead in preporcessing/translating. This is interesting due to that most other planners, do not having this step due to working directly with the PDDL. 
	
		\begin{table}[h]
			\centering
			\caption{problem 4v2}
			\label{prob4v2}
			\begin{tabular}{lllll}
				& Universal & Existential  \\
				total Time & 9.8 & 5.2 \\
				translator Time& 7.1  & 2.2 \\
				
				
				relevant atoms & 6742 & 8199\\
				auxiliary atoms & 13900 & 14710\\
				final queue length & 20642 & 22909\\
				total queue pushes & 40653 & 44321\\
				axioms & 1 & 534 \\ 
				peak memory & 71356 KB & 66040 KB\\ 
				task size &29496 & 31067 \\
				
				
				preprocessing Time & 2.6 & 2.8 \\
				necessary operators & 5469 & 5485 \\
				
				
				search Time & 0.1 & 0.2 \\
			\end{tabular}
		\end{table}
	%wich domain
	An anomaly is shown in prob4v2 table \ref{prob4v2} (where a single stone is add to problem04) and not much difference would be expected, but here the planner figures out that the objects is in fact not movable, and the explosion of axioms dosnt happen. 

	
	Another way of tweaking the code is to optimize the Problem Definition, this can be done by removing unreachable states/objects, more precise remove the representation of position that isn't useful. The effect of this can clearly be seen when adding unused location to prob02 and the results are shown in table \ref{whitespace}. The results shows for each variation the time need roughly doubles. Interestingly enough the version of the domain with existential quantifiers isnt effected nearly as much by it (table \ref{times}). 
	one version scales with the size of the problem (grounding), the other with the number of objects (axiom explosion). This shows that long running times does not necessary correlate to a more complex problem. It also especially for universal quantifier version shows the weakness of a general planner, which is that it cant use specific knowledge of the domain, and therefore cant easily discard non relevant areas of the problem.
	
	
	\begin{table}[h]
		\centering
		\caption{level 4}
		\label{lvl4}
		\begin{tabular}{lllll}
			& Universal & existential  \\
			total Time& 175.4 & x \\
			translator Time& 164.4 &  \\
			
			
			relevant atoms & 27782 & \\
			auxiliary atoms & 40327 & \\
			final queue length & 68109 & \\
			total queue pushes & 201441 & \\
			axioms & 13 &  \\ 
			peak memory & 231780 KB &  KB\\ 
			task size & 138081 & \\
			
			preprocessing Time& 10.0 &  \\
			necessary operators & 24525 & \\
			
			search Time & 1.0 &  \\
		\end{tabular}
	\end{table}
	
	\begin{table}[h]
		\centering
		\caption{level 9}
		\label{lvl9}
		\begin{tabular}{lllll}
			& Universal & existential  \\
			total Time&  & x \\
			translator Time& 429.9 & \\
			
			
			relevant atoms & 82572 & \\
			auxiliary atoms & 61255 & \\
			final queue length & 143827 & \\
			total queue pushes & 494482 & \\
			axioms & 5 &  \\ 
			peak memory & 537248 KB &  KB\\ 
			task size & 405030 & \\
			
			
			preprocessing Time& & x \\
			necessary operators & & x \\
			
			
			search Time &  & x \\
		\end{tabular}
	\end{table}
	
	
	
	
	
	\begin{table}[h]
		\centering
		\caption{white space. for each version the width of the problem have been increased by 5}
		\label{whitespace}
		\begin{tabular}{lllll}
			& prob02 & prob02v2 & prob02v3 & prob02v4\\
			total Time & 11.2 & 24.0 & 49.3 & 91.0\\
			translator Time& 7.6 & 17.8 & 38.8  & 75.5\\
			
			
			relevant atoms & 12394 & 22257 & 34922  & 50387\\
			auxiliary atoms &14389 & 20021 & 25656  & 31291\\
			final queue length &26783 & 42278 &60578  & 81678\\
			total queue pushes & 58980 & 101633 & 155153 & 219523\\
			axioms & 1 & 1  & 1 & 1 \\ 
			peak memory & 100800 KB & 157492 KB & 229452 & 317760\\ 
			task size & 56625 &  104505 & 166385 & 242265\\
			
			
			preprocessing Time& 2.4 & 5.8 & 9.9  & 24.5 \\
			necessary operators & 10774 & 20079  & 32184 & 47089\\
			
			
			search Time & 0.2 & 0.4 & 0.6  & 1.0\\
		\end{tabular}
	\end{table}
	%	\begin{table}[h]
	%		\centering
	%		\caption{level 4}
	%		\label{lvl4}
	%		\begin{tabular}{lllll}
	%			 		   & forall & simple  \\
	%			total Time &  &  \\
	%			translator Time&  &  \\
	%			
	%			
	%			relevant atoms & & \\
	%			auxiliary atoms & & \\
	%			final queue length & & \\
	%			total queue pushes & & \\
	%			axioms &  &  \\ 
	%			peak memory & KB &  KB\\ 
	%			task size &  & \\
	%
	%
	%			preprocessing Time& &  \\
	%			necessary operators & & \\
	%
	%
	%			search Time &  &  \\
	%		\end{tabular}
	%	\end{table}
	
	\begin{table}[h]
		\centering
		\caption{Running times}
		\label{times}
		\begin{tabular}{llllllllllllllllllll}
			& prob00 & prob01& prob02& prob02v2& prob02v3& prob02v4& prob02v5& prob03\\
			universal 	& 0.892  &0.887  &11.326 &24.798   &52.617   &95.08    & x       &0.794    \\
			existential &0.646   &0.788  &6.777  &12.148   &18.863   &27.405   &36.86    &0.704  \\
		\end{tabular}
		\begin{tabular}{llllllllllllllllllll}
			&  prob04& prob04v2& prob07&  prob09& prob10& prob11& prob12 & level 4\\
			universal    &23.905  &9.197      &36.326   &5.842  &13.45  &2.4 2           &21.484 &429.9\\
			existential      &124.794 &4.434   &14.228 &2.444  &5.789  &1.713        &7.346 & x\\
		\end{tabular}
	\end{table}
	
	
	

	\subsubsection{Parameters}
	The main parameter is the choice of heuristic. This choice is fairly limited due most of the heuristics supported by fast downward dosnt support the use of axioms or doesnt do it well. The choice of heuristics only effect the total time used very little due to the major bottle necks being translating and preprocessing.
	
	
	%todo test data of different heuristics



