\section{Tests}

%quality
%
%domain
%level04.pddl
%translate+preprocess
%187.649
%0.984
%plan lenght: 35
%
%level25small.pddl
%translate+preprocess
%299.333
%5.4
%plan lenght: 32
%
%
%level07.pddl
%translate+preprocess
%514.073
%116.042
%plan lenght: 45
%
%no update
%
%level04.pddl
%translate+preprocess
%7.498
%0.248
%plan lenght: 35
%
%level25small.pddl
%translate+preprocess
%4.637
%no plan
%speed



	
	%the PDDL Domain description 
	%how does it handle when the possible action increase
	%how does it handle when the problem size increase


	There are various ways of tweaking the performance of the planner. The two most obvious ways of doing this, is changing the parameters of the planner and changing the PDDL domain to fit the planners strengths better. The latter part is where the update and classic approach comes in.
	% comparrison

		\subsection{Plan Quality}
		% quality of the soloution
			
			%table of results.....
			%wich heuristic is used FF
			
						\begin{table}[h]
							\centering
							\caption{Plan Quality}
							\label{quality}
							\begin{tabular}{llllll}
								& level 4 & level 7  & level 25small & problem 24 & problem 24v2\\
								classic & 35 & 45 & x&11&11\\
								update& 35 &45& 32&7&11\\
							\end{tabular}
							Length of the found plans
						\end{table}
			
			%run on toy problem that shows post processing
			Comparing the two main approach and looking at results in table \ref{quality}, it can be seen that on problems where the assumption holds the found solutions are equal. Some difference can be seen where the post processing is necessary (problem 24 and 24v2 where the robot is activated to late). The post processing can in most cases be optimised to perform close or equal to the update approach. However to achieve the best possible result from the post processing domain specific knowledge would be need.	A greater difference is seen on levels such as level 25, where the assumptions used in the classic approach fails completely (moving objects needs to hit each other). The number of levels where this is the case is fairly limited. As one would expect it can be seen that domain only effect the quality of the solution where the assumptions made does not hold.
			
			
		\subsection{Speed}
		% speed
			When looking at the data in table \ref{prob4} its worth taking note of that most of the time is not always spend in search, as one would expect for a planner, but instead in preprocessing and translating. 
			
			This is interesting since it tells something about what the planner have problems with.
			that the problem lies in the representation of the problem and not the complexity of it. this is supported by the problem being a simple one which also is reflected in the search time.
			
			%This is interesting due to that most other planners, works more directly with the PDDL description (dont translate to SAS+), and therefore does not have to use the same amount of time on this step.
		
			A significant speed advantage to the classic approach can be seen on all problems it can solve. The difference in speed was expected, due to the domain type being relaxed and more similar to the ones used in the IPC. One would therefore expect the planner to be more optimized for this kind of problem.
			

			%why the large difference.....
			What wasn't expected was how large the difference. On a problem such as level 4 is the difference roughly a factor of 20, it is however worth taking note of that the speed difference isnt equal for all the sub parts of the search. It is in particular the translator which is the bottle neck. 
			
			%what can be done about it
			The great speed difference makes the update approach less useful. For the it to be able to solve more complex levels this speed difference needs to be reduced. Test have shown that the use of universal quantifiers have a large impact on the translating/instantiation time. Therefore there is created a variation of the domain where a single universal quantifier is replaced by an existential quantifier and an extra action(s).(code can be found at Appendix \ref{Domain_Variation})
			%comparing existential and universal


			\begin{table}[h]
				\centering
				\caption{problem 4}
				\label{prob4}
				\begin{tabular}{lllll}
					& forall & simple  \\
					total Time & 26.2 & 136.2 \\
					translator Time& 21.9 & 6.6 \\
					
					
					relevant atoms & 8872 & 12968\\
					auxiliary atoms & 16959& 18807\\
					final queue length &25831 & 31775\\
					total queue pushes &58904 & 68537\\
					axioms & 1 & 132652 \\ 
					peak memory & 100568 KB & 208356 KB\\ 
					task size & 42751 & 573269\\
					
					
					preprocessing Time& 4.2 & 127.4 \\
					necessary operators & 7292 & 7337\\
					
					
					search Time & 0.1 & 2.2 \\
				\end{tabular}
			\end{table}
			%insert table of running times
			When running the different versions of the domain on various problems, one thing becomes clear, the total times varies greatly depending on the domain and level combination (table \ref{times}). However when looking at the results (table \ref{prob4}), what shows is that the use of universal quantifiers greatly increases the instantiation/translation time. 
			
			Replacing the universal quantifiers ensures a quicker instantiation/translation, but it has the cost of the number of axioms exploding, and in general the number of atoms growing by 5-20\%, which in the end can greatly hampers the preprocessing that generates the Causal graph.
			
			The tendency seams to be that the more movable objects and complex the problem the better the version with universal quantifiers does, this is especially clear when moving from toy problems to actual levels (tabel \ref{lvl4} and \ref{lvl9}). Generally the existential variation of the domain only really shines when the problem is "small" and isnt therefore useful on the different more complex levels in Astro Kid.
			
			\begin{table}[h]
				\centering
				\caption{problem 4v2}
				\label{prob4v2}
				\begin{tabular}{lllll}
					& Universal & Existential  \\
					total Time & 9.8 & 5.2 \\
					translator Time& 7.1  & 2.2 \\
					
					
					relevant atoms & 6742 & 8199\\
					auxiliary atoms & 13900 & 14710\\
					final queue length & 20642 & 22909\\
					total queue pushes & 40653 & 44321\\
					axioms & 1 & 534 \\ 
					peak memory & 71356 KB & 66040 KB\\ 
					task size &29496 & 31067 \\
					
					
					preprocessing Time & 2.6 & 2.8 \\
					necessary operators & 5469 & 5485 \\
					
					
					search Time & 0.1 & 0.2 \\
				\end{tabular}
			\end{table}
			%wich domain
			An anomaly is shown in prob4v2 table \ref{prob4v2} (where a single stone is add to problem04, see figure \ref{prob04v2}) and not much difference would be expected, but here the planner figures out that the objects is in fact not movable, and the explosion of axioms dosn't happen. 
			
%			\subsection{Problemdefinition}
			Another way of tweaking the code is to optimize the Problem Definition, this can be done by removing unreachable states and objects, more precise remove the representation of position that isn't useful. The effect of this can clearly be seen when adding unreachable location to prob02\ref{prob02} and the effect can be most clearly seen in table \ref{whitespace} for the update approach. The results shows for each variation the time needed roughly doubles. Interestingly enough the version of the domain with existential quantifiers isnt effected nearly as much by it (table \ref{times}). One version scales with the size of the problem (grounding), the other with the number of objects (axiom explosion). This shows that long running times does not necessary correlate to a more complex problem. It also shows the weakness of a general planner, which is that it cant use specific knowledge of the domain, and therefore cant easily discard non relevant areas of the problem. Even though the update approach is used to illustrate the point its not restricted to this approach. The classic approach isn't effected ass much but goes from 2.2s (prob02) to 5.5s (prob02v4) which is still an increase of a 100\% without the complexity of the problem changing.
			
			The simplest way to optimise using this information, is to trim the edges of the problems. Doing this dosn't require much knowledge, and can be done on nearly any kind of domain.	An even better optimization can be achieved by actually analysing the possible paths in the problems, eg. most of the fields under the platforms are unreachable in \ref{prob02}. The problem here is that to actually realise this for a given level is often more or less equivalent to actually solving it, this is especially the case for more complex and compact levels. 
		
			
			\begin{table}[h]
				\centering
				\caption{level 4}
				\label{lvl4}
				\begin{tabular}{lllll}
					& Universal & existential  \\
					total Time& 175.4 & x \\
					translator Time& 164.4 &x  \\
					
					
					relevant atoms & 27782 & x\\
					auxiliary atoms & 40327 &x \\
					final queue length & 68109 &x \\
					total queue pushes & 201441 &x \\
					axioms & 13 & x \\ 
					peak memory & 231780 KB &x  KB\\ 
					task size & 138081 &x \\
					
					preprocessing Time& 10.0 &  x\\
					necessary operators & 24525 & x\\
					
					search Time & 1.0 &x  \\
				\end{tabular}
			\end{table}
			

						\begin{table}[h]
							\centering
							\caption{level 9}
							\label{lvl9}
							\begin{tabular}{lllllll}
								& classic  & Universal & existential\\
								total Time& 11.5 & 301.7 &x \\
								translator Time& 5.6& 280.3 & x\\
								
								
								relevant atoms & 8797& 61431 &x \\
								auxiliary atoms & 169254 & 64980 &x \\
								final queue length & 178051& 126411 &x \\
								total queue pushes & 746595& 359476 &x \\
								axioms &  265& 23 &x \\ 
								peak memory & 195568 KB& 386872 KB &x \\ 
								task size & 43197& 265076 &x \\
								
								
								preprocessing Time& 5.4 & 17.2 &x \\
								necessary operators & 4283 & 49496 &x \\
								
								
								search Time & 0.5 & 4.2 &x \\
							\end{tabular}
						\end{table}
			
			
			
			
			\begin{table}[h]
				\centering
				\caption{Adding White space to the domain.}
				 For each version of the problem the width have been increased with 5 by adding air to the edge of the problem.\\ The approach used is the update approach
				\label{whitespace}
				\begin{tabular}{lllll}
					& prob02 & prob02v2 & prob02v3 & prob02v4\\
					total Time & 11.2 s& 24.0 s& 49.3 s& 91.0 s\\
					translator Time& 7.6 s& 17.8 s& 38.8 s & 75.5 s\\
					
					relevant atoms & 12394 & 22257 & 34922  & 50387\\
					auxiliary atoms &14389 & 20021 & 25656  & 31291\\
					final queue length &26783 & 42278 &60578  & 81678\\
					total queue pushes & 58980 & 101633 & 155153 & 219523\\
					axioms & 1 & 1  & 1 & 1 \\ 
					peak memory & 100800 KB & 157492 KB & 229452 KB& 317760 KB\\ 
					task size & 56625 &  104505 & 166385 & 242265\\
					
					
					preprocessing Time& 2.4 s& 5.8 s& 9.9 s & 24.5 s \\
					necessary operators & 10774 & 20079  & 32184 & 47089\\
					search Time & 0.2 s& 0.4 s& 0.6 s& 1.0 s\\
				\end{tabular}
			\end{table}
			%	\begin{table}[h]
			%		\centering
			%		\caption{level 4}
			%		\label{lvl4}
			%		\begin{tabular}{lllll}
			%			 		   & forall & simple  \\
			%			total Time &  &  \\
			%			translator Time&  &  \\
			%			
			%			
			%			relevant atoms & & \\
			%			auxiliary atoms & & \\
			%			final queue length & & \\
			%			total queue pushes & & \\
			%			axioms &  &  \\ 
			%			peak memory & KB &  KB\\ 
			%			task size &  & \\
			%
			%
			%			preprocessing Time& &  \\
			%			necessary operators & & \\
			%
			%
			%			search Time &  &  \\
			%		\end{tabular}
			%	\end{table}
			
			\begin{table}[h]
				\centering
				\caption{Running times}
				\label{times}
				\begin{tabular}{llllllllllllllllllll}
					& prob00 & prob01& prob02& prob02v2& prob02v3& prob02v4& prob02v5& prob03\\
					universal 	& 0.892 s  &0.887 s &11.326 s &24.798 s  &52.617 s  &95.08    & x       &0.794 s  \\
					existential &0.646 s  &0.788 s  &6.777 s &12.148 s  &18.863 s  &27.405   &36.86 s  &0.704 s  \\
				\end{tabular}
				\begin{tabular}{llllllllllllllllllll}
					&  prob04& prob04v2& prob07&  prob09& prob10& prob11& prob12 & level 4\\
					universal    &23.905  &9.197      &36.326   &5.842  &13.45  &2.4 2           &21.484 &429.9\\
					existential      &124.794 &4.434   &14.228 &2.444  &5.789  &1.713 s        &7.346 s & x\\
				\end{tabular}
			\end{table}


\subsection{Heuritics}
The main parameter in Fast Downward that can be tweaked is the heuristic. This choice of heuristic is fairly limited due most of the them supported by fast downward dosnt support the use of axioms or conditional effects, which are used in the domain description, and those heuristics that does, do so barely\footnote{(in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) \url{http://www.fast-downward.org/Doc/Heuristic}}. The only supported heuristic that is admissible is Blind, and as the name suggest isnt the most advanced of the heuristics.

The importance of the choice heuristic varies greatly depending on the level. and if speed, quality or a combination is wished for. For the update approach choice of heuristic is fairly unimportant since the bottleneck is at the translator and preprocessing. When looking at the classic approach this changes. The effect of the heuristic on the different levels varies greatly, eg. on level 4 the time consumed by the search(heuristic) is minor. when looking at the heuristics performance over a wider array of problems, some things appears.

The heuristics blind and context enhanced additive both does well on all the level except a single one each. 

The additive heuristics consistently gives fast results but solutions of a poor quality.

The blind heuristic gives a high quality due to it being admissible and it is fast except on a single level where it is 60 time slower than the second to last.

The simplest possible explanation for why some heuristics does terrible on some levels, is that they cant handle axioms well and will therefore handle certain situations "stupid"\footnote{Fast downwards description of the situation..}. This cant explain why Blind fail, due to i fully supporting all features of the domain. The reason for the failure instead lies in that its an uninformed search, which means that the no knowledge of the domain is used and is therefore prone to explore the state space less efficient. Therefore it is not unexpected that blind fails on a level, but more that it dosnt fails on other levels. That this does not happen, must be credited to the preprocessing of the problem.


This leaves the heuristics FF and Max which are not the fast but does not have any notable problems. with FF being the on average bit Faster than Max, and will therfore be used further on.





%heuristics
%	admissible
%		blind
%
%
%	additive
%	Context-enhanced additive
%	causal graph
%	FF
%	max

	\begin{table}[h]
		\centering
		\caption{level 4}
		\label{tablvl4}
		translate+preprocess
		7.425 s\\
		\begin{tabular}{lll}
			name & time (s)& lenght\\
			Additive & 0.329 & 35\\
			blind & 0.196 & 35\\
			ContextEnhancedAdditive & 0.193 & 35\\
			causalGraph & 0.182 & 35\\
			ff & 0.19 & 35\\
			max & 0.188 & 35\\
		\end{tabular}
	\end{table}
	
	\begin{table}[h]
		\centering
		\caption{level 7}
		\label{tablvl7}
		translate+preprocess
		8.086 s\\
		\begin{tabular}{lll}
			
			name & time (s)& lenght\\
			add & 1.5 & 77\\
			blind & 14.8 & 76\\
			Context-enhanced additive & 13.1 & 76\\
			causal graph & 17.47 & 76\\
			ff & 22.0 & 76\\
			max & 26.9 & 76\\
		\end{tabular}
	\end{table}
	
	\begin{table}[h]
		\centering
		\caption{level 10}
		\label{tablvl10}
		translate+preprocess
		21.248 s\\
		\begin{tabular}{lll}
			
			
			name & time (s)& lenght\\
			Additive & 0.878 & 34\\
			blind & 2.174 & 34\\
			ContextEnhancedAdditive & 0.717 & 34\\
			causalGraph & 1.024 & 34\\
			ff & 0.755 & 34\\
			max & 1.326 & 34\\
		\end{tabular}
	\end{table}
	\begin{table}[h]
		\centering
		\caption{level 14}
		\label{tablvl14}
		translate+preprocess
		12.389 s\\
		\begin{tabular}{lll}
			
			
			name & time (s)& lenght\\
			Additive & 12.719 & 273\\
			blind & 11.367 & 158\\
			ContextEnhancedAdditive & 104.799 & 181\\
			causalGraph & 20.722 & 158\\
			ff & 33.153 & 158\\
			max & 28.949 & 158\\
		\end{tabular}
	\end{table}
	
	\begin{table}[h]
		\centering
		\caption{level 32}
		\label{tablvl32}
		translate+preprocess
		24.389 s\\
		\begin{tabular}{lll}
			
			name & time (s)& lenght\\
			Additive & 0.934 & 20\\
			blind & 131.198 & 17\\
			ContextEnhancedAdditive & 0.712 & 17\\
			causalGraph & 2.213 & 17\\
			ff & 0.748 & 17\\
			max & 0.961 & 17\\
		\end{tabular}
	\end{table}
\subsection{Remarks on general planning and Astro Kid}
	The Astro Kid world can be represented in PDDL, but the domains use of continuous actions, forces the representation to either be relaxed, or made in an awkward way, where the planner have trouble handling it. For PDDL to be able handle the Astro Kid domain properly, there needs to be introduced a proper way of handling concurrency.

	The Update approach guaranties to give a valid optimal solution, due to simulating the complete domain. This approach however have the cost of time and memory used. This is due to the domain not fitting well into the classical domain. The variations of this approach shows this clearly by also getting into problems. In general the update approach is only useful on domain where the assumption for the classic approach does not hold, due to large speed difference an nearly equal quality of the found plans. Even then it only works on simple domains, since it often fails to find a solution due to finite memory and time constraints.

	Relaxing the domain ensures that a solution is found quickly, but this solutions is not always valid. This can in some cases be solved by adding noOps at appropriate places. Adding noOps to the the plan when necessary takes a little away form the idea of using the general planner, by requiring some specialised knowledge about the domain, that cant easily be reused on other domains.
	
	The heuristics causal graph, FF and Max have shown to be the most reliable of the available heuristics with a slight advantage to FF. Where all produces fast solutions of a good quality. 
	
	The combination of heuristics as FF and classic approach means that unless the few unsolvable less critical, Fast Downward solve the task and thereby making a purpose build planner superfluous.