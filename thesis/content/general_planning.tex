	\chapter{The Astro Kid World}
	%general description of the world
	The Astro Kid game is a discrete world where everything moves in a 2D grid, and the world is fully observable. It's a single agent system based around the actions, which can be started by controlling the avatar. These player actions are movement (up, down, left, right), push, and activate control. These are the actions which the player controls, and everything else are consequences of theses actions. This means that these actions are the only ones where the planner have a choice that can effect the final result. (a brief overview of the objects in the domain can be found in appendix \ref{rules})
	
%	An example of this is the movement of robots (slide and fall) which has a precondition, which can only happen as an effect of an player action. at the same time all actions involving robot are mutually exclusive, so only a single one is applicable at any given time.
	
	% What? Dårligt beskrevet.
	Actions that do fall into this category of consequences, can be such as a robot walking forward when started, objects falling when push over an edge etc. The difference between the two groups is that the planner should not be able to stop an object from falling mid air, but it should be able to chose if the player moves left or right. 
	

	% What? Dårligt beskrevet.
	When looking at the Astro Kid domain, it is worth noting the main areas where it differs from classical planner domains like the Gripper. These areas are concurrent and continuous actions. Continuous actions are defined as actions that happens over several time steps. The continuous actions all relates to the movement of objects (falling, sliding and walking). An example of this is that falling from the top of the map to the bottom doesn't happen instantaneous, but in steps and it has to pass through the areas in between. As a result of this multiple objects can move at the same time, which leads to concurrent actions.
	
	The number of simultaneous concurrent actions are limited, since effects of continuous actions can't increase the number of moving objects. This means that a maximum of one new action with continuous effect, can be started each step. An example of this can be seen on level 25 (\ref{level25}). This level also illustrates that even though one action can be started each turn, the total number is limited by the finite size of the map. In this case a maximum of eleven stones and the avatars can be moving at the same time.

\chapter{General Planning}
	The idea of using a general planner is that it is possible to solve the problem efficiently, without building a planner from scratch, for each problem. The general planer will however nearly often be less efficient than an planner for the specific problem. This is due to it not always being able recognize and utilize features that are specific to a given domain. The main question is therefore if the general planner can solve the problem efficiently enough to be useful.

	To begin solving the problem with a general planner, the domain needs to be described in a planning language. In this case PDDL is suitable choice since it is a expressive language and used for the IPC, and there therefore exists a series of planners that support this language.
 
	  
%	complete PDDL not fully supported by most planners
	% hvad er fast downward? Hvordan virker det?
	The general planner there will be used is Fast Downward\footnote{\url{http://www.fast-downward.org/}}. Fast Downward was chosen due to it being a widely know open source planner and it has done well in several IPCs, eg. won the Sequential Satisficing and Optimization parts of IPC 2011\footnote{\url{http://www.plg.inf.uc3m.es/ipc2011-deterministic/Results.html}}. It must therefore be considered one of the top planers out there, even though it only support a subset (PDDL 2.2 level 1 + action cost) of the complete PDDL. This therefore the use of PDDL is limited to this subset. 
	%One of the things that differentiate Fast Downward from other planners is that it dosnt directly use PDDL for the planning but instead translates it to SAS+ before trying to solve the problem. 
 
 \section{PDDL}
	Due to how the domain differentiate from the type of problems usually found in classical planning. There are used two different approaches to describe the domain in PDDL. The domain can either be relaxed into a more classical planning domain or use the structure as is, and work around the problems that occur due to it.
	
	%TODO describe relaxation
	Relaxation is based on simplifying the problem by removing or loosen some constraints. This makes it easier to find solutions, but it will not necessarily be valid ones. Invalid solutions can sometimes can be transformed to valid ones using domain specific knowledge.
	
	\subsection{Problem Representation}
		% basic structure grid predicates and so on...
		There are several approaches to the problem, but the basic structure of the problem remains the same. The differences between the approaches lie in the actions available and the ordering of these. 


		This is possible due to PDDLs separation of Problem and Domain description. The main part of the problem description is the location of the different objects in the domain. Theses locations are by representing each point in the world's 2D grid as an object and defining its location relative to its neighbours. All other objects locations in the domain are then defined relative to these locations.
		\begin{lstlisting}
(relativ-dir pos-01-01 pos-02-01 right)
(at stone01 pos-01-01)
		\end{lstlisting}
		
		%item representation. object or predicate

		
		Even though the domain description changes, how the metric is used remains the same for both domains. The planner can either be optimised towards plan length or cost. This is useful since the found plan by the planner consist of both player action and consequences actions. The plan length will therefore differ from the number of player actions. Since the quality of solution is solely based on player action, the consequence action needs to be filtered out when the planner finds a solution. this can be done by adding a cost to the player actions while every other action has cost zero, and let the planner optimize by cost instead of the total length of the plan.		

		
		\subsection{Classic Approach}
		What will further on be described as the "Classic Approach" is built around getting the domain to be more similar to that of a classical planning problem. 

		This approach is centered around avoiding an input update loop, and keeping the separation of when an action is applied on the domain when all it's consequences are applied on the domain as direct as possible. The main advantage of doing this, is that general planners are optimized for this kind of problem, since that is what they usually handle at the IPC.
		
		% Classic approach
		The main problem area with the classical approach is that PDDL doesn't directly allow concurrent actions, unless they are changed/merged into a single action. This could be done by having an action for each possible combination of objects moving, and thereby describing every possible interaction between the objects. This approach would however leads to an explosion of possible actions, since the number of actions would then be exponential depend on the number of objects that can have a continuous effect. %The scaling would therefore be terrible (insert number)
		Another problem with having the number of actions dependent on the number of objects, is that domain would then either have to be limited to a certain number objects or change depending on the number of objects in the problem description. This would be against how PDDL is intended to be used. 
		%Another problem with this approach is that the domain then either only would work with a limited number or objects or the domain needs to change depending of the number of objects in the problem
	
		To avoid this problem, the domain can be relaxed by making some assumptions, so it would fit better into a classic planning paradigm. The assumption is that moving objects don't interact with each other. This means that concurrency can be avoided, by letting one of the concurrent actions completely terminate, before the next is considered. 
		% volapyk
		To avoid the avatar from standing still unnecessary when executing the plan, only agent actions is considered as part of the solution (when executing the plan the agent doesn't wait for concurrent actions to stop).
		
		This assumption makes the states in-between the continuous actions' start and end states irrelevant for the solution. In the ideal world it would therefore be possible to apply a single of the actions with continuous effect and treat it as a normal action due to the only interesting state being the last of the continuous action. However even with this assumption it isn't feasible to calculate which state a given continuous actions ends in, due to it depending on all the states in between (worst case everything in the domain). It could be done by using PRC or recursion but neither is supported by PDDL.
		
		
		%why is this a good assumption
		The assumption holds in most cases due to objects generally moves away from the avatar (actions such as fall, slide, walk, and push). Which also means that any subsequent action won't interfere with others, due to objects moving at same speed. Teleporters, remote controls, and gates can in a few cases interfere with this. When this assumption holds, it would be possible to find the optimal solution.
		
		Applying the assumption however means that minor discrepancies between the real world and the PDDL world can occur. The differences can in some cases be ignored since, what is important, is that the avatars route is clear. If the discrepancies can't be ignored e.g. if problems occurs between multiple moving objects. An example of this can be seen eg. on level 31 (\ref{level31}, here the multiple objects needs to move concurrent with the correct timing. The assumption can then in most cases be ensured by inserting noOps (no operation, do nothing) into the plan after a solution is found and thereby ensuring only one thing moves at the time as the assumption requires. 
		This however results in a solution which is not necessarily optimal, and there will still be a few instances where this isn't enough. A case where this would be a problem is if two moving objects needs to interact (e.g. hit each other \ref{level25}) to solve the problem. In such a case the problem cant be solved, due to the limitations of the assumption.
			
		Using this approach means that each action needs a rather large set of preconditions, this is to ensure that not only is the preconditions for the given action fulfilled, but also that no other action with continuous effect is unfinished. 

		The main precondition for most of the actions are therefore a condition that ensures that nothing else is moving (continuous effect). In general several different things is handled in each action, and they are in most cases the same for several other actions. %The use of axioms could solve the copy paste problem but that kills the performance.
		
		There are a few cases where this isn't the case, since they are not restricted by other actions. In the case of gates opening and closing, they are handled by a derived predicate (axioms) instead. 
		Further more to simplify the precondition and effects of the actions, part of the functionality are extracted into their own optional actions. This the case for picking up items and teleportation. They are in fact not an optional action, but due to their locations works well as optionals. And in the case of teleportation it is possible to treat it as optional action, using post processing since it is reversible.
		
		\subsection{Update Approach}
		% other approach
		Due to the problem with a few unsolvable levels in the classic approach, and the wish of obtaining good solutions without post processing, a different approach is needed. The main idea with this approach, is the idea of using the domain as it is, this is to avoid making assumption on the domain, which then can effect the quality of the found solutions. Basically it is to ensure that the PDDL version of the world is and react at all times the same as the real world. This approach therefore guarantees an optimal and valid solution is possible to find from the domain.
		
		When looking at the domain there are two types of actions: The ones where the planner has a choice (player action), and actions which are consequences of earlier actions. The main idea is therefore to separate the domain into choice and update, and then enforcing an ordering of the actions so a choice is always followed by an update. The ordering of actions can be enforced by using flags. This ordering makes it possible for the action to be limited in purpose and therefore to have fewer and simpler preconditions, and thereby making it more readable.
		
		The update step is in itself split up into multiple parts with a strict ordering, to enforce that the concurrent actions interact correctly with each others. The update step is separated into: removing objects, changing direction of objects, moving objects, collecting items, opening/closing gates, teleportation. To ensure all the continuous effects are applied on the relevant objects universal quantifiers are used. 
		
		A problem with this approach is how the strict ordering of actions (choice update cycle), differentiates from the approach usually used in general planning. This means the direct link between action and effect is not as clear as in classic PDDL. This is due to the update sequence delaying when effects of an action later applied. 
		
	
			%try with the axiom gate

	
	

